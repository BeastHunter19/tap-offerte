services:
  logstash:
    build: ./logstash
    hostname: logstash
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      XPACK_MONITORING_ENABLED: "false"
    depends_on:
      topics:
        condition: service_completed_successfully
  broker:
    image: apache/kafka:3.9.1
    hostname: broker
    container_name: broker
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT_HOST://broker:9092,PLAINTEXT://broker:19092"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENERS: "CONTROLLER://:29093,PLAINTEXT_HOST://:9092,PLAINTEXT://:19092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      CLUSTER_ID: "81ec01f9-d33e-4f75-a302-4791512b850a"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
  topics:
    image: apache/kafka:3.9.1
    hostname: topics
    container_name: topics
    command: >
      bash -c "
      /opt/kafka/bin/kafka-topics.sh --create --topic pdf-metadata --bootstrap-server broker:9092
      "
    depends_on:
      - broker
  crawler:
    build: ./crawler
    volumes:
      - shared-storage:/data
      - ./test_flyers:/tmp
    depends_on:
      - logstash
    environment:
      - LOGSTASH_HOST=logstash
  spark:
    build: ./spark
    hostname: spark
    container_name: spark
    ports:
      - "4040:4040"
    secrets:
      - gemini_api_key
    environment:
      - GOOGLE_API_KEY_FILE=/run/secrets/gemini_api_key
      - KAFKA_SERVER=broker:9092
      - KAFKA_TOPIC=pdf-metadata
      - ELASTIC_HOST=elasticsearch
      - ELASTIC_PORT=9200
      - ELASTIC_FLYERS_INDEX=flyers
      - ELASTIC_OFFERS_INDEX=offers
      - GEMINI_PROMPT_FILE=/opt/tap/prompt.txt
      - GEMINI_SYSTEM_PROMPT_FILE=/opt/tap/system-prompt.txt
      - SPARK_PARALLELISM=10
      - SPARK_CHECKPOINTS_LOCATION=/tmp/checkpoints/
      - EMBEDDINGS_URL=http://embeddings:8000/embeddings
    volumes:
      - sparklibs:/opt/spark-ivy-cache
      - ./spark/app:/opt/tap
      - shared-storage:/data
    depends_on:
      topics:
        condition: service_completed_successfully
    command: >
      /opt/spark/bin/spark-submit
      --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/opt/spark-ivy-cache -Divy.home=/opt/spark-ivy-cache"
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.4,org.elasticsearch:elasticsearch-spark-30_2.12:9.0.2
      /opt/tap/tap-offerte.py
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.2
    mem_limit: 2 GB
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 5s
      timeout: 10s
      retries: 20
    ports:
      - "9200:9200"
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
  index:
    image: curlimages/curl:latest
    depends_on:
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./elasticsearch:/elasticsearch:ro
    environment:
      - ES_HOST=http://elasticsearch:9200
    entrypoint: ["sh", "/elasticsearch/init-index.sh"]
  kibana:
    hostname: kibana
    image: docker.elastic.co/kibana/kibana:9.0.2
    ports:
      - 5601:5601
    volumes:
      - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
      - ./kibana/start-kibana.sh:/usr/local/bin/start-kibana.sh:ro
    depends_on:
      - elasticsearch
    secrets:
      - kibana_saved_objects_encryption_key
    environment:
      - ENCRYPTION_KEY_FILE=/run/secrets/kibana_saved_objects_encryption_key
    entrypoint: ["/usr/local/bin/start-kibana.sh"]
  embeddings:
    image: michaelf34/infinity:latest-cpu
    hostname: embeddings
    container_name: embeddings
    ports:
      - "8100:8000"
    volumes:
      - model-cache:/app/.cache
    command: >
      v2
      --model-id BAAI/bge-m3
      --port 8000
      --engine optimum

volumes:
  shared-storage:
  sparklibs:
  elastic-data:
  model-cache:

secrets:
  gemini_api_key:
    file: ./secrets/gemini_api_key.txt
  kibana_saved_objects_encryption_key:
    file: ./secrets/kibana_saved_objects_encryption_key.txt
